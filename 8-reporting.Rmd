---
title: "Data Analysis & Reporting"
output: html_notebook
---

```{r setup, echo=F, results='hide'}
Sys.setenv(R_NOTEBOOK_HOME = getwd())
library(ggplot2)
source("config.R")
source("helpers.R")
```

> This R notebook can be executed from within R, you can update the database connection properties and the dataset settings in the `config.R` file, or run the commands specified here interactively if you want to experiment.

In the last section of the artifact, all the graphs, tables & values used in the paper will be recreated. 

## Fig 1 - Heatmap

```{r}
heatmap = read.csv(paste(DATASET_PATH, "/heatmap.csv", sep=""), header = F, col.names = c("pid", "stars", "commits", "files", "originalFiles","containsClones"))
createHeatmap(DATASET_NAME, DATASET_PATH, "commits")
```

## Table 1 - Corpus

For total, non-forked and unique URL project counts, run the scc preprocessor (replace the second argument with other language of your choice):

```{bash}
cd $R_NOTEBOOK_HOME
cd tools/sccpreprocessor/src
java SccPreprocessor stats ../../../ghtorrent/projects.csv JavaScript
```    

The rest of data is provided in the following snippet:

```{r}
f <- function() {
    sql.connect(username = DB_USER, password = DB_PASSWORD, dbname = DATASET_NAME, host = DB_HOST)
    println("Counts:")
    println("  Projects downloaded      ", sql.query("SELECT COUNT(*) FROM projects"))
    println("  Projects analyzed        ", sql.query("SELECT COUNT(*) FROM projects WHERE files > 0"))
    println("  Files analyzed           ", sql.query("SELECT COUNT(*) FROM files"))
    println("Means:")
    println("  Files per project        ",mean(sql.query("SELECT files FROM projects")[[1]]))
    println("  SLOC per file            ",mean(sql.query("SELECT fileSLOC FROM files JOIN stats ON files.fileHash = stats.fileHash")[[1]]))
    println("  Stars per project        ",mean(sql.query("SELECT stars FROM projects")[[1]]))
    println("  Commits per project      ",mean(sql.query("SELECT commits FROM projects")[[1]]))
    sql.disconnect()
}
f()
```

## Table 2 - File Level Duplication

```{r}
f <- function() {
    sql.connect(username = DB_USER, password = DB_PASSWORD, dbname = DATASET_NAME, host = DB_HOST)
    totalFiles = sql.query("SELECT COUNT(*) FROM files")[[1]]
    fileHashes = sql.query("SELECT COUNT(*) FROM stats")[[1]]
    tokenHashes = sql.query("SELECT COUNT(DISTINCT tokenHash) FROM stats")[[1]]
    sccDup = sql.query("SELECT COUNT(id) FROM (SELECT fileId1 AS id FROM CCPairs UNION SELECT fileId2 AS id FROM CCPairs) AS x")[[1]]
    println("Total files                ", totalFiles)
    println("File hashes                ", fileHashes, " (", fileHashes/totalFiles, "%)")
    println("Token hashes               ", tokenHashes, " (", tokenHashes/totalFiles, "%)")
    println("SCCdupfiles                ", sccDup)
    println("SCCuniquefiles             ", tokenHashes - sccDup, "(", (tokenHashes - sccDup) / totalFiles, "%)")
    sql.disconnect()
}
f()
```

## Fig 3 - File Level Duplication

This graph has been created in Excel from the data in Table 2 above.

## Table 3 - File Level Duplication Excluding Small Files

```{r}
f <- function() {
    sql.connect(username = DB_USER, password = DB_PASSWORD, dbname = DATASET_NAME, host = DB_HOST)
    totalFiles = sql.query("SELECT COUNT(*) FROM files JOIN stats ON files.fileHash = stats.fileHash WHERE totalTokens >= 50")[[1]]
    fileHashes = sql.query("SELECT COUNT(*) FROM stats WHERE totalTokens >= 50")[[1]]
    tokenHashes = sql.query("SELECT COUNT(DISTINCT tokenHash) FROM stats WHERE totalTokens >= 50")[[1]]
    sccDup = sql.query("SELECT COUNT(id) FROM (SELECT fileId1 AS id FROM CCPairs UNION SELECT fileId2 AS id FROM CCPairs) AS x JOIN files ON id = fileId JOIN stats ON files.fileHash = stats.fileHash WHERE totalTokens >=50")[[1]]
    println("Total files                ", totalFiles)
    println("File hashes                ", fileHashes, " (", fileHashes/totalFiles, "%)")
    println("Token hashes               ", tokenHashes, " (", tokenHashes/totalFiles, "%)")
    println("SCCdupfiles                ", sccDup)
    println("SCCuniquefiles             ", tokenHashes - sccDup, "(", (tokenHashes - sccDup) / totalFiles, "%)")
    sql.disconnect()
}
f()
```

## Fig 4 - File Level Duplication Excluding Small Files

This graph has been created in Excel from the data in Table 3 above.

## Table 4 - Inter Project Cloning

```{r}
f <- function() {
    sql.connect(username = DB_USER, password = DB_PASSWORD, dbname = DATASET_NAME, host = DB_HOST)
    println("Projects analyzed          ", sql.query("SELECT COUNT(*) FROM projects WHERE files > 0"))
    println("Clones >=50%               ", sql.query("select count(*) from (select distinct cloneId from projectClones where cloneCloningPercent >= 50 union select distinct hostId from projectClones where hostAffectedPercent >= 50) as combined"))
    println("Clones >=80%               ", sql.query("select count(*) from (select distinct cloneId from projectClones where cloneCloningPercent >= 80 union select distinct hostId from projectClones where hostAffectedPercent >= 80) as combined"))
    println("Clones 100%                ", sql.query("select count(*) from (select distinct cloneId from projectClones where cloneCloningPercent = 100 union select distinct hostId from projectClones where hostAffectedPercent = 100) as combined"))
    println("exact dups                 ", sql.query("select count(*) from (select distinct cloneId from projectClones where cloneCloningPercent = 100 and hostAffectedPercent = 100 union select distinct hostId from projectClones where cloneCloningPercent = 100 and hostAffectedPercent = 100) as combined"))
    println("exact dups (>= files)      ", sql.query("select count(*) from (select distinct cloneId from projectClones where cloneCloningPercent = 100 and hostAffectedPercent = 100 and cloneTotalFiles >= 10 union select distinct hostId from projectClones where cloneCloningPercent = 100 and hostAffectedPercent = 100 and hostTotalFiles >= 10) as combined"))
    sql.disconnect()
}
f()
```

## Fig 5 - Percentage of project clones at various levels of overlap.

This graph has been created in Excel from the data in table 4 above.

## Table 5 -  Number of tokens per file within certain percentiles of the distribution of file size.

```{r}
f <- function() {
    sql.connect(username = DB_USER, password = DB_PASSWORD, dbname = DATASET_NAME, host = DB_HOST)
    x = sql.query("SELECT totalTokens FROM files JOIN stats ON files.fileHash = stats.fileHash")[[1]]
    sql.disconnect()
    quantile(x, c(.20,0.30,.45,.55,.70,.80,.90))
}
f()
```

## Table 6 - Corpus for Metadata Analysis.

```{r}
f <- function() {
    sql.connect(username = DB_USER, password = DB_PASSWORD, dbname = DATASET_NAME, host = DB_HOST)
    println("Projects analyzed          ", sql.query("SELECT COUNT(*) FROM projects WHERE files > 0"))
    println("Projects with 1+ commits   ", sql.query("SELECT COUNT(*) FROM projects WHERE files > 0 AND commits > 0"))
    sql.disconnect()
}
f()
```

## Fig 10 - Files per project distributions.

```{r}
logHistogramFromDF(heatmap, "files", DATASET_NAME, "Files per Project", "% of Projects", "Hist_files_per_project.pdf")
```


## Fig 11 - SLOC per file distributions.

```{r}
logHistogram(DATASET_NAME, "SELECT fileSLOC FROM files JOIN stats ON files.fileHash = stats.fileHash ORDER BY RAND() LIMIT 1000000", DATASET_NAME, "SLOC", "% of projects", "Hist_sloc_per_file.pdf")
```


## Fig 12 - Stars per project distributions.

```{r}
logHistogramFromDF(heatmap, "stars", DATASET_NAME, "Stars", "% of Projects", "Hist_stars_per_project.pdf")
```


## Fig 13 - Commits per project distributions.

```{r}
logHistogramFromDF(heatmap, "commits", DATASET_NAME, "Stars", "% of Projects", "Hist_commits_per_project.pdf")
```

## Table 7 -  Summary statistics for the entire dataset.

```{r}
f <- function() {
    sql.connect(username = DB_USER, password = DB_PASSWORD, dbname = DATASET_NAME, host = DB_HOST)
    println("Files per project")
    print(summary(sql.query("SELECT files FROM projects")[[1]]))
    println("Bytes per file")
    print(summary(sql.query("SELECT fileBytes FROM files JOIN stats ON files.fileHash = stats.fileHash")[[1]]))
    println("Lines per file")
    print(summary(sql.query("SELECT fileLines FROM files JOIN stats ON files.fileHash = stats.fileHash")[[1]]))
    println("LOC per file")
    print(summary(sql.query("SELECT fileLOC FROM files JOIN stats ON files.fileHash = stats.fileHash")[[1]]))
    println("SLOC per file")
    print(summary(sql.query("SELECT fileSLOC FROM files JOIN stats ON files.fileHash = stats.fileHash")[[1]]))
    println("Distinct tokens per file")
    print(summary(sql.query("SELECT uniqueTokens FROM files JOIN stats ON files.fileHash = stats.fileHash")[[1]]))
    sql.disconnect()
}
f()
```

## Table 8 - Summary statistics for the minimum set of files (distinct token hashes).

```{r}
f <- function() {
    sql.connect(username = DB_USER, password = DB_PASSWORD, dbname = DATASET_NAME, host = DB_HOST)
    println("Files per project")
    print(summary(sql.query("SELECT COUNT(*) FROM (SELECT MIN(projectId) AS pid, COUNT(*) AS cnt FROM files JOIN stats ON files.fileHash = stats.fileHash GROUP BY tokenHash) AS x WHERE x.cnt = 1 GROUP BY x.pid")[[1]]))
    println("Bytes per file")
    print(summary(sql.query("SELECT AVG(fileBytes) FROM stats GROUP BY tokenHash")[[1]]))
    println("Lines per file")
    print(summary(sql.query("SELECT AVG(fileLines) FROM stats GROUP BY tokenHash")[[1]]))
    println("LOC per file")
    print(summary(sql.query("SELECT AVG(fileLOC) FROM stats GROUP BY tokenHash")[[1]]))
    println("SLOC per file")
    print(summary(sql.query("SELECT AVG(fileSLOC) FROM stats GROUP BY tokenHash")[[1]]))
    println("Distinct tokens per file")
    print(summary(sql.query("SELECT AVG(uniqueTokens) FROM stats GROUP BY tokenHash")[[1]]))
    sql.disconnect()
}
f()
```

## Table 9 - Summary statistics for the minimum set of files (distinct file hashes).

```{r}
f <- function() {
    #SELECT COUNT(*) FROM (SELECT MIN(projectId) AS pid, COUNT(*) AS cnt FROM files GROUP BY fileHash) AS x WHERE x.cnt = 1 GROUP BY x.pid
    sql.connect(username = DB_USER, password = DB_PASSWORD, dbname = DATASET_NAME, host = DB_HOST)
    println("Files per project")
    print(summary(sql.query("SELECT COUNT(*) FROM (SELECT MIN(projectId) AS pid, COUNT(*) AS cnt FROM files GROUP BY fileHash) AS x WHERE x.cnt = 1 GROUP BY x.pid")[[1]]))
    println("Bytes per file")
    print(summary(sql.query("SELECT fileBytes FROM stats")[[1]]))
    println("Lines per file")
    print(summary(sql.query("SELECT fileLines FROM stats")[[1]]))
    println("LOC per file")
    print(summary(sql.query("SELECT fileLOC FROM stats")[[1]]))
    println("SLOC per file")
    print(summary(sql.query("SELECT fileSLOC FROM stats")[[1]]))
    println("Distinct tokens per file")
    print(summary(sql.query("SELECT uniqueTokens FROM stats")[[1]]))
    sql.disconnect()
}
f()
```

## Next Steps

[Language specific reporting](9-reporting-other.nb.html) in file [`9-reporting-other.Rmd`](9-reporting-other.Rmd).
